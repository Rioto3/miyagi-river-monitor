name: 宮城県河川情報スクレイピング
on:
  schedule:
    # 毎日午前9時(日本時間)に実行 = UTC 0:00
    - cron: '0 0 * * *'

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: リポジトリをチェックアウト
        uses: actions/checkout@v3
        with:
          ref: release # releaseブランチを使用
          fetch-depth: 0 # 履歴を全て取得
      
      - name: mainブランチの内容を取得
        run: |
          git fetch origin main
          # スクリプトファイルのみをmainからreleaseにコピー
          git checkout origin/main -- scraper.py requirements.txt
      
      - name: Python 3.9のセットアップ
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          cache: 'pip'
      
      - name: 依存パッケージのインストール
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: スクレイピングの実行
        run: python scraper.py
      
      - name: jqのインストール確認
        run: |
          if ! command -v jq &> /dev/null; then
            echo "jqをインストールします"
            sudo apt-get update
            sudo apt-get install -y jq
          fi
      
      - name: 結果ファイルをコミットして変更を確認
        id: check_changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          # 新しい記事のCSVファイルとメタデータJSONファイルをステージング
          git add new_river_articles_*.csv miyagi_river_metadata.json
          # 変更があるか確認
          if git diff --staged --quiet; then
            echo "変更はありません。"
            echo "has_changes=false" >> $GITHUB_OUTPUT
          else
            echo "変更があります。コミットします。"
            git commit -m "更新: 宮城県河川情報 新しい記事 $(date +'%Y-%m-%d')"
            echo "has_changes=true" >> $GITHUB_OUTPUT
            # 最新のCSVファイル名を出力
            latest_csv=$(ls -t new_river_articles_*.csv | head -n 1)
            echo "latest_csv=$latest_csv" >> $GITHUB_OUTPUT
          fi
      
      - name: 変更をreleaseブランチにプッシュ
        if: steps.check_changes.outputs.has_changes == 'true'
        uses: ad-m/github-push-action@master
        with:
          github_token: ${{ secrets.GHUB_TOKEN }}
          branch: release
      
      - name: 通知を送信
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          # 最新のCSVファイルを処理
          latest_csv="${{ steps.check_changes.outputs.latest_csv }}"
          echo "処理するCSVファイル: $latest_csv"
          
          # 全メッセージを作成するための変数を初期化
          all_messages=""
          
          # ヘッダー行をスキップして2行目から処理する
          tail -n +2 "$latest_csv" | while IFS= read -r row; do
            # CSVの行を分解
            date=$(echo "$row" | cut -d',' -f1 | tr -d '\r\n')
            title=$(echo "$row" | cut -d',' -f2 | tr -d '\r\n')
            url=$(echo "$row" | cut -d',' -f3 | tr -d '\r\n')
            
            # 空行または不完全な行はスキップ
            if [ -z "$date" ] || [ -z "$title" ] || [ -z "$url" ]; then
              continue
            fi
            
            # 個別のメッセージを作成
            message="🌊 宮城県河川情報ニュース速報 🚨\n\n📅 日付: ${date}\n📰 タイトル: ${title}\n🔗 リンク: ${url}"
            
            # 全メッセージに追加（間に区切り線を入れる）
            if [ -n "$all_messages" ]; then
              all_messages="${all_messages}\n\n-------------------\n\n${message}"
            else
              all_messages="${message}"
            fi
            
            # 個別のメッセージを送信
            curl -L -X POST \
              -H "Content-Type: application/json" \
              -d "{
                \"message\": \"$message\",
                \"x-api-key\": \"${{ secrets.MAKANA_LINE_API_KEY }}\"
              }" \
              "${{ secrets.MAKANA_CALL_URL }}"
            
            # 通知間の遅延（必要に応じて）
            sleep 2
            
          done